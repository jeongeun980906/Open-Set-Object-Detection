{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from  config.config import get_cfg\n",
    "from model.rcnn import GeneralizedRCNN\n",
    "from engine.optimizer import build_optimizer,build_lr_scheduler\n",
    "\n",
    "from data.build import (\n",
    "    build_detection_test_loader,\n",
    "    build_detection_train_loader,\n",
    ")\n",
    "from data.mapper import DatasetMapper\n",
    "import data.transforms as T\n",
    "from data.phase_1 import load_voc_instances,VOC_CLASS_NAMES\n",
    "from structures.image_list import ImageList\n",
    "from engine.detection_checkpointer import DetectionCheckpointer\n",
    "from data.utils import build_augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('./config_files/voc.yaml')\n",
    "cfg.MODEL.SAVE_IDX = 13\n",
    "cfg.MODEL.RPN.USE_MDN=False\n",
    "cfg.MODEL.ROI_HEADS.USE_MLN=False\n",
    "cfg.MODEL.RPN.AUTO_LABEL = True\n",
    "cfg.MODEL.ROI_HEADS.AUTO_LABEL = False\n",
    "cfg.log = False\n",
    "cfg.MODEL.ROI_HEADS.AF = 'baseline'\n",
    "NUM_CLASSES = 20\n",
    "NUM_CLASSES += 1\n",
    "cfg.INPUT.RANDOM_FLIP = \"none\"\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "# cfg.merge_from_list(args.opts)\n",
    "RPN_NAME = 'mdn' if cfg.MODEL.RPN.USE_MDN else 'base'\n",
    "ROI_NAME = 'mln' if cfg.MODEL.ROI_HEADS.USE_MLN else 'base'\n",
    "MODEL_NAME = RPN_NAME + ROI_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GeneralizedRCNN(cfg).to('cuda:0')\n",
    "state_dict = torch.load('./ckpt/{}/{}_{}_5000.pt'.format(cfg.MODEL.ROI_HEADS.AF,cfg.MODEL.SAVE_IDX,MODEL_NAME))\n",
    "model.load_state_dict(state_dict)\n",
    "model.proposal_generator.SSL_MODEL.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = '/data/private/OWOD/datasets/VOC2007'\n",
    "split = 'train'\n",
    "data = load_voc_instances(DIR_NAME,split,VOC_CLASS_NAMES,phase='t1',COCO_CLASS=False)\n",
    "mapper = DatasetMapper(is_train=True, augmentations=build_augmentation(cfg,True))\n",
    "data_loader = build_detection_train_loader(data,mapper=mapper,total_batch_size=1)\n",
    "VOC_CLASS_NAMES_NEW = (*VOC_CLASS_NAMES, 'unknown')\n",
    "loader = iter(data_loader)\n",
    "it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(it)\n",
    "batched_inputs = next(loader)\n",
    "images = model.preprocess_image(batched_inputs)\n",
    "features = model.backbone(images.tensor)\n",
    "gt_instances = [x['instances'].to(model.device) for x in batched_inputs]\n",
    "proposals, proposal_losses,gt_instances = model.proposal_generator(images, features, gt_instances)\n",
    "\n",
    "image = batched_inputs[0]['image']\n",
    "inputs = {\"image\": batched_inputs[0]['image'], \n",
    "            \"height\": batched_inputs[0]['height'], \"width\": batched_inputs[0]['width']}\n",
    "# proposals = model._postprocess(gt_instances,[inputs],images.image_sizes)\n",
    "height = inputs.get(\"height\", images.image_sizes[0][0])\n",
    "width = inputs.get(\"width\", images.image_sizes[0][1])\n",
    "\n",
    "\n",
    "new_size = (height, width)\n",
    "output_width_tmp = width\n",
    "output_height_tmp = height\n",
    "scale_x, scale_y = (\n",
    "        output_width_tmp / gt_instances[0].image_size[1],\n",
    "        output_height_tmp / gt_instances[0].image_size[0],\n",
    "    )\n",
    "output_boxes = gt_instances[0].gt_boxes\n",
    "output_boxes.scale(scale_x, scale_y)\n",
    "output_boxes.clip(gt_instances[0].image_size)\n",
    "\n",
    "file_name = batched_inputs[0]['file_name']\n",
    "demo_image = cv2.imread(file_name)\n",
    "boxes = output_boxes.tensor\n",
    "labels = gt_instances[0].gt_classes\n",
    "for label,bbox in zip(labels,boxes):\n",
    "    if label == 20:\n",
    "        color = (255,255,0)\n",
    "    else:\n",
    "        color = (0,255,0)\n",
    "    cv2.rectangle(demo_image, (int(bbox[0]), int(bbox[1])), \n",
    "                            (int(bbox[2]),int(bbox[3])), color, 1)\n",
    "demo_image = cv2.cvtColor(demo_image, cv2.COLOR_RGB2BGR)\n",
    "plt.imshow(demo_image)\n",
    "plt.savefig('./dummy/proposals/{}'.format(it))\n",
    "plt.show()\n",
    "it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('conda': virtualenv)",
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}